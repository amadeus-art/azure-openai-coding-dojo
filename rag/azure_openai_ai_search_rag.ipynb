{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Retrieval Augmented Generation (RAG) with Azure OpenAI and Azure AI Search\n",
    "\n",
    "In this notebook we will showcase how to implement a Retrieval Augement Generation pipeline using Azure AI Search.\n",
    "\n",
    "## Environment setup\n",
    "Before executing the following cells, make sure to set the following environment variables in the `.env` file or export them:\n",
    "* `AZURE_OPENAI_KEY`\n",
    "* `AZURE_OPENAI_ENDPOINT`\n",
    "* `MODEL_DEPLOYMENT_NAME`\n",
    "* `EMBEDDING_DEPLOYMENT_NAME`\n",
    "* `VECTOR_STORE_ADDRESS`\n",
    "* `VECTOR_STORE_PASSWORD`\n",
    "* `INDEX_NAME`\n",
    "\n",
    "<br/>\n",
    "<img src=\"../assets/keys_endpoint.png\" width=\"800\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mpronesti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mpronesti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain==0.1.16 python-dotenv langchain_openai azure-search-documents azure-identity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "import os\n",
    "\n",
    "from langchain.vectorstores import AzureSearch\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "openai_api_version = \"2024-02-01\"\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=os.getenv('EMBEDDING_DEPLOYMENT_NAME'),\n",
    "    openai_api_version=openai_api_version,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    ")\n",
    "\n",
    "embedding_function = embeddings.embed_query\n",
    "\n",
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the vector store on Azure\n",
    "\n",
    "The following vectorstore will be used to store the embeddings of the documents we will index.\n",
    "\n",
    "To enable semantic ranking, we need to create a semantic configuration in the Azure portal.\n",
    "- From Indexes on the left-navigation pane, open an index.\n",
    "- Select Semantic Configurations and then select Add Semantic Configuration.\n",
    "- The New Semantic Configuration page opens with options for selecting a title field, content fields, and keyword fields. Only searchable and retrievable string fields are eligible. Make sure to list content fields and keyword fields in priority order.\n",
    "\n",
    "<br/>\n",
    "<img src=\"../assets/semantic_ranker_ai_search.png\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "index_name: str = \"ai-academy\"\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=os.getenv('VECTOR_STORE_ADDRESS'),\n",
    "    azure_search_key=os.getenv('VECTOR_STORE_PASSWORD'),\n",
    "    index_name=index_name,\n",
    "    embedding_function=embedding_function,\n",
    "    fields=fields,\n",
    "    # needed for semantic ranking\n",
    "    semantic_configuration_name = 'my-config',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Populate the vectorstore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this notebook, we've scraped some langchain's blogs (see `data/`) we will store in the vectorstore."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "429"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_loader_kwargs={'autodetect_encoding': True}\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    '../data/langchain_blog_posts/',\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs=text_loader_kwargs,\n",
    "    #silent_errors=True\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "len(docs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(page_content='URL: https://blog.langchain.dev/7-24-release-notes/\\nTitle: [Week of 7/24] LangChain Release Notes\\n\\nNew in LangSmith\\n\\nStreaming in the playground: The playground now supports streaming! You can enter the playground by clicking on the “Open in Playground” button on the upper right hand corner of select runs.\\n\\nThe playground now supports streaming! You can enter the playground by clicking on the “Open in Playground” button on the upper right hand corner of select runs. Infrastructure changes to support more users: We’ve beefed up our backend. That means more of you off the waitlist soon!\\n\\nWe’ve beefed up our backend. That means more of you off the waitlist soon! UI and navigation enhancements: We’ve made a lot of quality-of-life improvements to the UI, mainly around the run details page. Biggest change is the trace tree is now on the left hand side. See the screenshot below for an up-to-date picture.\\n\\nNew in Open Source', metadata={'source': '..\\\\data\\\\langchain_blog_posts\\\\blog.langchain.dev_7-24-release-notes_.txt'})"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "['ZDZlOGRjODYtODMyYy00OTQ1LWE3YzgtMzRjODUxMTJlNjI0',\n 'ODIwZjhkNjUtOWUwZC00MWRiLWI3MGUtOTFhODU3MGU4ZjYx',\n 'OGI1YzZhYzAtMWMzMi00MzY5LWE4MzMtYmI0ZWNhMGFlNmQw',\n 'MThjMmRhYzQtZDc1OS00NzI0LTkwMmQtM2I5NmE4YjA0OGE4',\n 'ZDA1ZTZhYmMtYjY1Yi00MjQ4LWE3N2YtZDgxNTc2YTE5MjJh',\n 'NTJkODVjOGUtYTU4NS00MWYzLWJhZjQtMDZmZjA3ZTUzYTQ2',\n 'YzMwNzY3MTQtOTI0MS00MTk4LWI0OTgtN2UwNWVjODdiNzQ4',\n 'YTIxNjg5YTYtZWY0Ny00YjA5LWExODUtYTE1YzBlYWM3Nzdk',\n 'NzhiNjE1YzYtMDRmNC00YzU0LWFjODAtMzVkNDM2M2I5Mzhj',\n 'ZGU2OWNhMDktYTNhZS00NDAwLWJkNjUtYWZjYTExYThlMjAz',\n 'NzAyMTBhOWYtMTk4OS00ZjYwLTk2NjItYzhkNTE1OTRiY2Iz',\n 'YmY4OTAzMzctOWVkNS00MTFiLWEzMWQtMjdhN2U4ZTEzMDgy',\n 'MWRiZjcxOTQtMWExZS00M2Y3LWJkMWEtMjhkMGY3NDc4Y2Jh',\n 'ZjRlOTcyMGYtN2UxMy00YTVmLWE4NDUtZDBiZGM4MGIzNWNi',\n 'NTM0Njk0NmEtNDVlMy00ODUyLWFmZGEtNjhjM2U4MDZmYWQw',\n 'OGU0YTM5MTMtNWM1MS00ZTliLTkzNWUtNmM0YmQ2OGFiNzQx',\n 'N2NiNDllYTQtZmRjMS00YzM4LTk0NDEtYzYyYjdhNjU0ZGRj',\n 'ZjM3ZWE4NjMtZTVlMC00NDRmLWE1ZjctOGIxYWQyMWVmYzJj',\n 'NmNlMjZlOGItM2I2My00YjVlLWIxMmEtYjlhNTE3ZTA0YjJj',\n 'ZTU0MjZkOGQtNzU1ZS00YjczLThkYWMtOTRmMzY1MmRhMDkx',\n 'N2Q3NzMxNzQtOTdjYS00ZTQ4LWEwMTQtZmE4NDFhOWVmMzRm',\n 'ZGRiYzk5ZjYtYWI4Yy00ODFlLWJjZmMtZGNlNDZiNDMzYTAz',\n 'MzliYjJlOWQtZWRjZC00YTA2LTliNTUtMzExYTg1ZTIxZmMw',\n 'MWNlZDdjZmUtOWZmOC00ZmYxLWIyMTctZTBiYzNlYzQ0ZDkz',\n 'YWMxN2Q2OTgtZTNhNi00Y2QwLWI3MjktZDQwOGVjMDMxM2I0',\n 'NDIxNDYzYjktNWU3ZS00NjRhLWE1YWEtNjMyOTRiYTY4NTgx',\n 'NTY2ODM0ZGItNmY5OS00YzI4LWJmMGUtMDY2MDllMjllYTRj',\n 'NzZjMGEyOTAtZGQ5Yy00NThhLTk1YjctNWI3Y2FhNmM3YmU5',\n 'NThmMGVjNDAtOGU1Yi00MWY2LTgwOGUtNTZmYzIxOGE0NTgx',\n 'ZDMzZmJmYWYtZjcxYy00NWU1LTk1ZDgtZWY1ZWZjOWNjYzM4',\n 'OGRhODk1MmYtNjYyNi00YTcyLTk0MzctYzUxMzI4NjIxMTQ2',\n 'YzVjYjhmYjEtMTU1ZC00MGYyLTk3NzMtYmI3NTBjOGIzZWM4',\n 'ZDQ1Y2M3NjAtYWQ1Mi00NDUwLTg1MGMtMmM4ZTQyOTZlOWZj',\n 'MDI1NGZiNzgtZTRhYi00ZDkzLWIwMDMtMGJhY2VhZmFkZmMy',\n 'YmQ4MjIzYWQtZWU2My00YWVkLWE5OTMtN2FkNzVhNmY4NTg4',\n 'MzQxMWNiNjAtYjMzNS00ODYzLTkwNjQtZjhkNDFlY2JhYmQ4',\n 'NzhkZjA0MzAtNDc3OS00OTc3LThjZGYtZjVhMTVlZmRmMGIz',\n 'OThkOGFlYTItM2IxMS00NzQxLWJkZTgtZTYzOTM0YWMzNDY3',\n 'YTU1OTk3OTktZWQwYS00NTAyLTliYjEtODY2MjgwNmU1NTg2',\n 'NzMzNDMxNjItNDMxMy00YzljLWIwMWQtODBlNzA4YzQ2NDg5',\n 'MjBkZGExOGUtODkxNS00NDc1LTkzM2MtYTVlNmEwODYxZTU2',\n 'ZDA2ZWFlNmEtOTE0OC00OThjLWE5ZmQtMjZlMmE2ODA5ZjRl',\n 'NmZkNzBjYzgtNzkxOC00ODk3LWJkODAtZTY3ZGYwZTkxMTMz',\n 'Y2VhYjg2NjgtMzlkYS00N2I5LWIzMjctZTk0MmQ5ZTVlZmRk',\n 'NDMyNzIxZDQtODcwYi00ZjhhLWE5YzYtMmEwZmUxY2M0Y2I1',\n 'YTNlYTE0MzUtZGQ4Zi00NGM5LTk4ZmUtYTJjYjhjYmJhZDZj',\n 'MTkyYWUyNzQtMTAzOS00NWVjLTkwNWYtMzMzZDg5Njk5ZmZl',\n 'ZWJhM2JkZjktNTE1Mi00M2UyLWJjMGQtNzI4ZGI4ZmI1NTY3',\n 'OTc2ODliMjEtNGJmMi00ZmVmLWI2OGUtYTVmZjY0ZGY5M2Y5',\n 'NDI5YWMwYjctNjI2YS00NzQyLTk3YzQtMzc0YzgyNjYxNjRj',\n 'NWUxMzNlN2YtMmUyNi00ZjhiLWJlNzgtNDMzMDMwMGIwYzQ2',\n 'MThlYjJhZGEtZjJkNC00MTdmLTg1NGQtNTc3Zjc3YTI0NWE5',\n 'MjIzMWFhNzktNThhMy00YzhmLTllMTItZDQxNWJhNWQ1ZDM1',\n 'NTMxYzMzNTEtOTY0ZC00NzE5LWI4MzItYjQ0Y2RkNmJjZWRm',\n 'NzdjMjNmNTYtZDE1Zi00NDMyLWEyNGQtYWRiZDQ4YzQzNmEy',\n 'ZmYwMGRhYjYtMGJmMC00ZjlmLTg5NDYtMGM4ZjQ5NjNkNmZh',\n 'Njk0MTY4NDgtZTcwYS00ZTk5LThmZmItNzA1NTgxZjdkZWVl',\n 'OWRhNTJkOTQtY2VmYS00OGI0LWFiM2EtN2Q4OTkyZjFhNzIz',\n 'Y2MwMTlkMGMtNjk5ZC00MzA1LTljMTItMGI4ZWIyY2M0MjY5',\n 'ZWNkZWJlMjEtNWFlMS00OGI2LTliZmQtMjMyYmM3Yjg4OTUx',\n 'M2E2NDU0MjMtZWM4Yi00MTkyLThmYzItOWU0MTZlMDI4OTIx',\n 'OTUxMmI4ZGEtMzRkNC00ZTMyLTlkMDUtNGMxNTVhMGU3YmFh',\n 'YjA3ODI4YzktOTMxZi00MGQ5LWExNTEtY2RiNTRjMTY3NmEw',\n 'ZGU4MGFlM2EtODM5Yi00OWJmLTlhOTktODZiZTAzZThjNGM4',\n 'MzQ2N2I1YzItY2U2Yy00NDhlLWI1NDctZjM3MWY2ZGNjNjM5',\n 'YTQ1OWY5MWEtYjg1Ni00MDczLThlYjctNWI0MDlmZjU2NTk4',\n 'MmZlZWZjYzItNzVjNi00Y2I0LTlkODctZDEzMTY0ZDcxZDk0',\n 'ZjliNjMxYjUtOWVlMS00ZjYyLThjOTMtOTU4MDBkNDQxMTBk',\n 'M2MyOTk5MWMtNTliMy00OTFhLThmNDAtN2Q2NTIyMDI3Yjcz',\n 'YzEzYjc1NzktNThjZS00YzI3LTg1ZGMtNGFlNGNjMDJmZjQy',\n 'YzNkZmU5NTAtNDg3OS00ZWMyLWJkZjItNTFkOWNmYWJmNzAz',\n 'NWM4NTMxMDMtNDA2Ni00Yzk0LThhNjctZjk5NGRmMzA3NmJh',\n 'YWQ2NzA4NWEtYWFmZi00ZjQxLWJhOGQtYjY0NjkwN2Q5MzI5',\n 'YjEwZGIzYWItNDYwOC00ZTdiLWJlYWUtZTU3OWUxYzI5OTI1',\n 'NTlhOWYxZmYtNTk5Mi00ZGQyLWJmYTctZjIzZThiNDNhODA4',\n 'MDk2ZmM3ZDgtNjgzYi00Y2RiLWE2OWMtZTYyYzU2NzM5M2Vl',\n 'N2YyNjcwZDktZTM1NS00MzRiLWI5NGQtMGMwMWQ2MjZmZTJl',\n 'N2MwYjdjNDItZmQzYi00M2Q3LWFlOWUtMzRmNjI3MTJhZThk',\n 'ZTdjNjA1MjUtMGIyZS00NDFkLWFkNDItOTRhMzc4ZDY5Y2Qz',\n 'OTI2NDYwNzItZjkzNC00YjVkLTg4MTctN2E0MzA0OTI4MDQy',\n 'ZjhjMTVjODctNTc2Mi00MDdmLTg2YWYtYzg5N2NmNDdiNTMz',\n 'ZjkzMGZhMTEtOWJjNy00ZmQ0LTllNTgtMGRhNzBlMjM1OGE1',\n 'MzEyMjQ4MTItM2RlMC00YTYwLThmMTItNzI4YzIwYmM5MDlh',\n 'NGNmNzNkYjItMmFjZS00MmM4LWJlYWEtMzgxNGY0YTFhYmMw',\n 'MWFhZDcyZTUtNTA0YS00YjM4LThhNTktOGQ0MGUxNTg0Yjc0',\n 'MzdlNzBhYjktNTc3OS00YzYzLWI3OTctOWRlYmRjYzZiYjA0',\n 'OTQ3ZmJkOTYtYWYyNC00NTdiLWIzN2MtMTk2Nzc3OTc5ZWY0',\n 'ZDdhZDUyYTUtM2ZlNC00ZmIyLWExYWEtMjY5ZThjNWEwYjNm',\n 'ODQ0NGMyZWItNjI5Ni00MWJiLTlkMzktMDgzMDFkZjBkNDhk',\n 'ZDk3YTFlNjctNWIwMS00M2IzLThmZDUtNDlkMGIwYzFmYjBl',\n 'MjdhYWQ1Y2UtY2EyMi00YzJiLTlmNzUtYjU4MDk5YjBkMTE4',\n 'YWFjOTM5ZGMtODZkMS00ZDg1LWE5NDItMmEwMjhiOWQzZDM3',\n 'YTUxMDkwMzItMThkMS00MTgwLTk4YzEtNzIwMzg5NmMwZGY0',\n 'NmYzMDNjYWEtYzY4MC00ZmNlLWE2MjQtY2EwY2VlOWQ4YzEy',\n 'ZjljZDk4N2UtZGJmNi00NjdmLWIzMzYtNTc5NWZlYzZhZTgy',\n 'ODcxODlhNDctMzNiOS00YWZhLTg2ODYtZTZhMWUwYTMyNzg0',\n 'NmRiNGM2NjktYmMwMS00ZTE3LTk5NWUtOTBmODdjZDY4MWMz',\n 'ZTk2Nzg3YzktZmE1ZC00YzY2LWFiMDYtMTc1MjgzODQyMWI1',\n 'ZWI2ZTA1N2UtNTNkZS00MzY2LWFlMmUtZDNlMTIzNWNmMWNi',\n 'NmZiNDU1ZDgtMmU4ZC00MTJlLWJjYWQtOTQ0Nzg4ZGRmMTBm',\n 'YzgzMWVlMzgtN2NmYy00MDY2LThmZjgtYTA4N2ZmMzYzZGJm',\n 'NGYzMTIzYTctMmZkYy00NmY1LTgzM2QtMzA0MjAwYjMxNDVj',\n 'NThjZWJmMGYtZTdhMi00YzE5LTkyYWItMWZlYmM4MWRjZDZh',\n 'Yjk4MTM4N2EtNjE4YS00NjljLTk5MzYtZTY4YjgxZjM4NjI5',\n 'ZGYyMzYxOGItYjM3YS00ZmY1LWFkNWQtYzQ3ZmJiYjBlYWE3',\n 'ZmZhZWUzOTAtYzg3Yi00ZDIzLTgwMDgtM2MyYWEzZWVjOWIw',\n 'ZTQxZjU5YzMtMGZmZi00NTdhLWE1NTQtYzdjMzZkOTc0OGMz',\n 'OTAxYzY1NGUtNTBiOS00ZmQ0LWI4OTktYjlhZDkzNGNkYWJj',\n 'NWVmYWExNTAtNzExZC00ZWM2LThjM2ItYzU4YzU2NjRkNjY2',\n 'MmFiYzk2NjYtZWQxNy00OGIzLWE0MGMtMmM1ZjFhNDk3ODEz',\n 'NzdjYjcxY2MtODYyMS00MWI0LThiMjktNjNmNjY0YjBlYjc0',\n 'Njk4NjVmZjUtYjExNi00Y2UxLWE0MTktYTNjNzBjZmM4ZWNl',\n 'OWU5NTVjMDMtZmYzYy00MGFkLTkwMWUtYWZhODg1YWI3N2Nl',\n 'YjE3NDUxNzMtMzI5MS00MmQwLWJhZGItZWU4Y2E1ZDI2ODU4',\n 'Mjc5OTY4ZmUtZDVjNy00YTIxLTg4OTgtOWU0NmRiNjgxNzg4',\n 'YjYyZTFhOTctMTExNi00NjZiLWEzMmItZWVhYzEyMjllNmFm',\n 'NjdmMDZjOTMtM2Q3NS00MGFjLWE2NjgtYmUwYTc3OGE4YzRm',\n 'NzI1NWQ4M2UtOGFlMC00NWE5LThmMTQtNTIxNmQ4NWI1MmEy',\n 'NTA5ZDJhZTUtM2VlYi00MDJhLTljNGItOTk2NTg2MjY2YzQy',\n 'ZmI1NjI2N2ItOTViMS00ZDY4LTlkOGYtNDI2N2EwNzVlYTgx',\n 'YTg4OTU0MTItM2IxMC00NDg2LWEzMWEtNDIyYmIwOWFkMWY4',\n 'OWZlOGViZTItMTc1YS00MTRkLThmNmYtYTM0OWJmYTc0NGYw',\n 'NWFiNjkzOTgtOGMyMS00ZTlmLWJjMTYtMmU4MzE5NGRlNDYy',\n 'YmM5NjQ0ODQtNWMzOS00NDQ0LTg1NzUtMTIzMzU2NzkxYjVi',\n 'MjU2OThmN2QtNGJjMC00ZDBjLThhNTktYmEyOTZmNGE3YzM4',\n 'NjlmMTYzNWMtZGE1ZC00ODQ0LWFjY2MtMmUyMWMxZTA3NTUx',\n 'NDk2YWRhNWEtZGVlYy00OGE0LTk3NTYtNTdhM2UyMTdlNjhh',\n 'ZTgwZTY1ZDgtM2Y3Zi00YmE4LWJjNDEtZjc2YzhmYjZhNjM3',\n 'NjE4MzIxM2UtZDlkYy00NWEzLWI2MDAtZDZlNTcwYzBhNjI4',\n 'MmZhOGJjMzUtZjQ3Zi00YzAxLThjOTctZjNlMzczNzNmMjQ0',\n 'ZDM2MjY1M2QtZGU3NC00NmE0LWFkMjgtZjNmNWZiM2ZiNDRh',\n 'MTJjMDFmNmQtMmFiOC00NzAxLTkwMmEtZjljODY4M2U3ODEy',\n 'MzllZTY0YTEtZmQ5Ny00YzQzLTliMTctODJmNjZkZDQyMGI2',\n 'MTk3YjQzOTYtMjJkYy00ZGUwLTk1ZWItNzI0NmNhZWFmYjBl',\n 'YmUyNGZkNWMtM2VjNi00MWMzLWFkZDEtMWI3NzRiMDI0ZjM5',\n 'YjZlNWI4YTYtNDM5Yi00OTY2LThiNzktNmE0NGI5N2U1ZDYw',\n 'YzQ2MDE1NDEtNTkzMi00OTBiLWE4OTItMDY5NjE0ZjY4ZWI3',\n 'Y2VjOGU0OTQtYzhlMS00ODIzLTk4NjMtOWQ0OGZjMmI2OWNm',\n 'ZDcyMzRhZjQtY2EzNi00ODhiLTljMGEtZjcwZjhkM2UwNTk0',\n 'M2EyMDk5NDEtOTQyNC00MWJiLThlNjktOTEzMDM2ODY4MGU4',\n 'M2M2MDFjZjItZDhlYS00ODljLTlhMWQtZjRjMWIxNTgwODBl',\n 'YmQzNmE3YjUtZTJkMC00OGQyLWI5OWItMmZmN2Q0OTdmYWZj',\n 'YjQ5NDNkYmMtMzFjMC00ZTUyLThmNTgtYzllMzdhZmIyZTVk',\n 'NjZjNGRmNDQtODM4YS00MjEwLTk2MGQtMDYyNzE2YjBkOTgw',\n 'OTZhNTU1MWYtNGJkYS00MDQzLWIyODQtYThhY2FmNTRlN2Ez',\n 'OWIxNTk5YTMtM2RmYi00YzVlLTg0YTAtNTM1NmNlMWFhYTM5',\n 'OWRkZTI4YTYtODNjZC00Y2IwLWI3YzEtMzc4Y2M2NDdhNWVm',\n 'YWQyY2YxN2YtOTY4NC00NzI5LThhNmYtZDYxMDAyMmMxMzk3',\n 'N2VmNGY0NWQtODI4Mi00ZmU1LWE5N2EtODkyNjBkNGNhNmI4',\n 'MmJmNDAwNzYtYTk4YS00NTRmLWE0N2EtYjU5NDI2ZGUxMjcz',\n 'ZTkxMjcxNmEtYjNkNS00YmFlLWEzMDAtNmM4NzdmNDNlNjUx',\n 'OWQzNjRhMWEtMTJhNS00Mzk2LWI4ODktYTNhM2E5NTUzZGM3',\n 'MjIxYTJjZDMtODM5Yi00NWM3LWI0MGEtNWQ4OWQ1NTgyNTM3',\n 'ZGQ2MzA2ZmYtZmRhZC00MjViLWI0MTEtODk4MmEyMjY2OTlj',\n 'MDYyNTYwN2ItMTk2OS00MDExLWIwZWMtMzhlOTRjYTliMzVk',\n 'YjVlM2I4YTktNGM2ZC00YjEwLTgzMDUtYmNiMjRhY2ZmMjUz',\n 'MTY5NjE2MzgtMzA3ZS00MzdhLWE5MmItZjRhYTZhNjQzZjQ1',\n 'ZDBjOGY3Y2QtZGVkYi00YzYyLTk1NDUtNjQ0ZGI3YWEyNmY5',\n 'M2FkOGI1ZWQtNGI3Ni00ZjE5LWE4ZGYtN2NiZmFkMzkyOTgy',\n 'NmQzOWUyYzMtODNmNS00YTc5LTllNTQtYzEzN2FlZTI1Yzk1',\n 'NWUxMzI4NjItNTgzYi00MzU3LWIyM2UtMzBkZjNkMWY3OTYz',\n 'NDA0ZjMwOWEtZDRjZS00YmQxLTgzNWUtNmZiNmMwNWFmMTli',\n 'NmU2YmQ1NDUtMTZkYi00MDVmLTg5OGYtMmU2ZDMxN2NmNGI3',\n 'N2E0NmY2ZWMtODJmNC00M2I5LThjMWEtOGQwNjlmNWUxMmFl',\n 'MzZlNDQ4ZmUtMzgyZS00MTg5LWE0ZTgtNWMxMDE4MzAxOWM4',\n 'NDIyMGRhYTMtOTllMC00ZmY5LWI5ZDYtOTQ2MjFhNDgwZjBj',\n 'ZDE1YWVjZTQtZjMxOC00NjcxLTg1N2UtM2NlYmI4NmEwY2Jh',\n 'Y2Y0YThiZmYtOWFhMC00YmVlLWI4ZWItM2FlNDM4ZGIzYzgx',\n 'YTRkYjZkMTktY2JlMy00Y2I4LWJmNDktODI3OTlmNjhkMzdi',\n 'MTA5ZGVhM2YtMjliMy00M2QzLWIzZTEtOTgxY2IyNTRlZjlm',\n 'NjBkOWEwYzktMzUyMy00NWMxLWJhYTYtMzZiYzM4Nzg0Yjg5',\n 'NTkzYjQ1YjgtOGI0Ny00MjBjLTkyMWItNTAxZDViMjY5YTcw',\n 'YjE2NmI0MDktYzZmOC00ZDc4LWE0YjMtMTE5MzM5OGY4YWUw',\n 'NDAyOWIzMzItMzAxNy00N2RlLWI5N2QtNDNjNzVhYjJkMDJm',\n 'ZDk2ZWVkYjEtY2IzYi00YzgxLTkxNDQtMzNkOWM3MDhmMzhk',\n 'YmY4NzU4ZTgtYjU4Ni00ZTAwLTgxN2ItNzY3NDZlMTAyNTc2',\n 'ODQzNzJjMzItOTdhOS00MjA3LTgxMmQtNDFhNTVkZGFhMGE0',\n 'MzJhNzgzODktZjhiMC00ODUyLWEyM2ItODc2MWUxNjRkZTUz',\n 'YzhkMDRiMjItMjJlMy00YzZlLTkxNzAtMjE3OTBkM2E0MDI0',\n 'MzJjZmJlY2MtMjkxZS00N2ExLWE0NjctZTBhYzgxNDRlY2Mz',\n 'Njg3ODY3ZTMtMDQyNy00MGJiLWFjNGUtNDMyZjg2ZmU1Yzk5',\n 'MjZjMTJiNmItYTMxMS00MzA3LThjOGQtYTQxZWVlNTA5ODEz',\n 'OGQ2ZTMwMGEtZWMyOC00NTk2LTlmN2QtZWQ0NjQ1MGJhZjQ2',\n 'ZjAwNzQ2MzEtZDM4YS00MDUxLThlMjYtOTM2ZTc1NDEyMzk5',\n 'OTQxN2VmOGUtODQyMi00ZDRlLTlkMmItMTJjYzQyZTMyYjdi',\n 'ZmQ1OTE1NmItZmQ0Zi00OGJlLWE4NDItM2VhNWJmZWE2NzVl',\n 'M2Q1ZTk1ODUtYTIyMS00OTYxLTg3M2MtYTBkNzMxNjg4ZGE2',\n 'NjMzNGMyMTEtZDk4OC00YmVlLTk1NjctYzUzYjk3ZDI2NDMw',\n 'OGVkYzdjOWItOWFlOS00NDVhLWJjNWQtNjkzYTFjMDliNTdi',\n 'OTAyZjMyMzQtOWE0Yy00MjYzLTk1NTEtNjY5NTliYTMyZTJh',\n 'NjYyZGY0MmUtMDNhYi00YjYzLTgxYzUtMGZlNjEyMWM1ZDQ2',\n 'ZTVhMTBjNGItZmQ2ZC00MTI0LTlmYjItOWU5NGViOTUxYzQ1',\n 'ZmM1OWIwZGUtYjAzZC00MDEzLWFhZjYtNDFjYjlmZDUyOTEz',\n 'ODYwYzJiNTUtNTUxYy00YTI2LTgxYzMtYzhmMWM1Y2UwMTM3',\n 'ZjE5M2M5MDQtM2EyNi00MmEzLWFjYTItZmY5MDZmNGQ2ZDg4',\n 'ODhjZmVkOGItNzA4MC00MGY0LWFhN2EtZDNjMTk5MmJkOWY1',\n 'NDU5MzA0NjItYTMyZC00MGM1LWE1YTQtZGUyMTcyMWZmYjlj',\n 'ODkxYjBhY2QtZTczOS00NjRlLWEyN2MtNTYzYThjMDc4OWFm',\n 'ZjA3Y2E0OWYtMTQyMS00MDQ2LWEyZmEtYTg5ODUwOWFkYjc1',\n 'M2Q1MjBiNjEtNjJkMC00YmJhLWJlZDgtNmI0OTEyOGNhYTVk',\n 'MDRmOTg3NzEtMTFkNi00ZThhLThiMmQtZTg3MTdkN2Y2YmM5',\n 'MmM5NjBlMzAtNjJhYS00ZWRiLTk3YTctNzVmMDU2NzFhMGFm',\n 'ZGFlZjZjMzgtMzk3Mi00ZDA4LTlmNTMtOWJmOWEyYTA1YTc2',\n 'NjMwMjUxZDgtNTQ2NC00Yzg2LWE2OGItZDJjZWMzMjNjYzE3',\n 'ZDE2MTE1NDQtNGYxMS00OTg3LWI2NGEtOGFkNDQ4MjNjZmE1',\n 'ZTIyYWVhZTctNTgwOS00N2U1LTg1NGEtMDI2MWZiOTA5YjVm',\n 'YWQ0NDJiNjEtYjFjMS00ODI5LTljNjEtYzljNWNhODA4YzMz',\n 'Nzk1NDMxYjItNTIxYS00YWYyLTk3MzAtZGZmYzUxMDRiYmE4',\n 'MGQ5NjliMmMtNjdhNS00MmY2LTgxMzgtOGNiNGU1NGIzZjll',\n 'NTQwNjk4ZDYtOWNkYy00Zjk3LWFiMjQtZjYwODVmMzNjNjk5',\n 'MDcyZWFkOTktMTVjZi00MTY0LTkyYWUtYmI5M2U0OGE2ODEy',\n 'MDNmMTRlYzAtOTk0ZS00YjM3LTllNWMtYmYzNjFhNzk0MTNh',\n 'Y2FiZmNlMjgtMDA4Ni00NDU5LTkyY2ItMWYxZDU0N2E1MWRk',\n 'YjVjYWIxMGQtNTY5OS00ZTY4LWEwZmYtZjg0MTFjNDViOTVk',\n 'Yzc2OTkxYjctNDM3OC00MWY0LWI5NGEtZjk0ZTA1MjcxYzEz',\n 'NjI0NzZlYzctZGY2ZC00NjM1LTk1MzEtZGYzOTBmZjQ3Y2Fm',\n 'ZWMwZWU5NWMtZDNjNC00OTU0LTg4OGYtMTA1YThhZDhkNDFk',\n 'MGQxOTdhMTQtMjg1MS00ZmQ1LTkzMzAtZTMyMWUzZGQyOGIw',\n 'ZjdjYmJjMmQtOGVlMS00ZjgyLWJjYWItYWZjM2U1ZjNhZjhm',\n 'M2FjZmMzMTctMTQ4My00NGNiLTgyMjUtYTY1NTAxNTZiOGI5',\n 'MzU1MzM1YTMtM2FiOC00MzZmLWE1NjItMTc5MmE1NTU4ZTVh',\n 'NWFlZWUzZGQtMWI3MS00NDllLTgzNDMtNTk4ZTE2OTE0YjM2',\n 'Yjg2MGJjZDMtNjg4ZS00MjA2LWI4ODktNGM1MjU2ZmQ5MmJm',\n 'ZGFhNWU1YzktMTRhYi00OGQ4LTk5YmMtZjc0NjMwMGFmMTli',\n 'NDNmOTA5MzctOTlkMS00MDcwLTgxZTktNTJlNjZiMjBjMmYw',\n 'ZTRkMzIyMjUtNjMzMS00ZDk0LWEwMDEtNzIzYjMwNjQ1NTdh',\n 'MTQyYjVkYmYtY2M1MS00YTgxLTk4OGItZTUzODBkYjZkNTg5',\n 'ZWIxMGIwYWQtNDZhZC00MDI2LWExZTctYTNhOGY3YzgyODI5',\n 'NTRmNWQ4NDgtMDgzZi00ZDJkLWE0NjUtODc3YTE5NDQxOTU2',\n 'NzIzMWU4M2ItMWFkNi00M2EyLTk0YzUtNjM4NmU4M2Y5ZmZk',\n 'MWIyMzM1NWMtNjhmMC00YTZjLTgzYzAtNDllYjcxYzU3NzVh',\n 'MTBmOWM5NjMtMmIxNy00NDhjLTgxZTMtZGUwYjhhNmVmZDY5',\n 'YWVjOTkyZjQtZDlhZi00OTAzLWE2MjktODIyYmUxZGIxZWEw',\n 'ZWE5NTkzZTgtZmUxOS00OTM5LWE5MzktZjU2NzBkOWUwMTRl',\n 'ZGI3MTExZGQtODkyZi00ZmZiLTlhZmEtYTMzOGZkODA1OWY0',\n 'NjlmYzE1MWYtMGI5NC00Y2ZiLWEwNGMtNmY1NmU0NmUzZmFi',\n 'OWU0MjI2Y2QtMGNkOS00ZTk2LThlMzgtYzc3Mzg1NWQ3ZTQ0',\n 'NjQ2NWVlZGEtZWUxZC00MWU4LThkZTYtMzJiOWQ4MDhlMjdl',\n 'Njk2YjkyZDEtODI3MC00NmZkLTg2NDctYTdiZGM1MmVmZmM3',\n 'OWJjNzA1OWEtZDE4Yi00NDU1LWIxMTUtNzdhYzE3MTJjNTg5',\n 'M2U5NjMyNzQtNDI0My00ODI2LTk5MTYtZWQ5MjE5ZjBhMzMx',\n 'Mzg5NzRkZDUtMDU2Yy00MzM2LWFiMGItN2I2NGFkNDY2NmEw',\n 'MTkyYmI0NWQtN2JkZC00YWM1LWExYjItNWZhMTAwNGY2YzJi',\n 'ZTA2NTJjOTgtNWVmMC00NzkwLWFiYTctMzZhMzM4MjIxYTgz',\n 'MjZhMzdjMzYtZTU0Ni00N2VkLWJjNjYtYTVkOWE0YTc4ZmIw',\n 'MjhiMTEzYjAtMWZhNS00Mzc2LTlhNjMtOTJhYjZjMmI5OTli',\n 'NWE0Yzk1NGItNGMwNS00OWJlLWE5ZmItYjY2MGE2ZDA5Yzdm',\n 'YjY1N2RhZDUtYzcwNy00MTEyLThiYzAtZWQ4NzhmNzI4YjY4',\n 'ZDU5ODNiZmUtNTdlYS00NTZlLWI0YWEtZDJkYTA4Y2U3ZmJj',\n 'N2IxNjNhNjMtMDBmMy00NmM3LTk3NTktNTIwOWU2NGY2MGI4',\n 'ZGExZTczYjQtOTYwNS00NGYxLWEzZWItOGYxYmIxOGVlNjU3',\n 'OGI2N2VmMjMtNTE2Yi00NTQ3LWE2ZjgtNGY1N2IyM2RjZjQ0',\n 'NzIzYTM0MTItMGE4NS00NTQwLWI4NzEtY2ZmOTEzY2ZmMDc2',\n 'MmExZjM2NjgtY2NjMC00M2ZhLWI0MjktODc5YWQzNTAzNjIz',\n 'MGE1NmNlOWUtYjJjYS00MjU1LTk2ZGYtODYzMzVhZjM3Mjlj',\n 'YmRiODBhMDQtMDI5Ny00MWRhLWJiZjktOTYzYzA5OWEzNDgx',\n 'YjRkYjE4MGUtYTY0Yy00YzY0LTlkODctOWVmOTMzNzZmY2I4',\n 'NmRkN2YyZDUtZTNmZC00YmYyLWFmMjAtZDBjMTAwM2M5ZTky',\n 'ODBhNDJlNWQtMTRjNS00YmRjLWI5MjYtY2JiZmU4ZjRkYjMx',\n 'OWMwZWI2ODEtOTcwYy00MTYyLWI5ZmUtYTRiNTI0ZDk5OWZk',\n 'OTRmNGYxOWUtZGVjMi00YjQ5LTg1ZWQtMTBkNGUyNzFiOTEx',\n 'ZDU4YzY1MjktYjM3Mi00MTc4LTkxZDctMmNkNzEwOWUzNWUy',\n 'YzRkMWM4MDAtM2I4OS00ODFlLWI0NTUtZTZiMjk5MDRiODMz',\n 'NTQ5M2ZmZTEtNWM5MS00OGM2LThjMjMtYzZhZDhmYzlmOTA5',\n 'N2I1MzNiYjEtZGY4My00M2VlLTljYzgtY2I4ZmNkMmM2NDM3',\n 'MDNiMzE1N2ItZGY5NS00MzkzLWIzOTYtZmY1ZDFkNjYwZTll',\n 'YTZiNDRjNDEtZDUxMC00MmRiLWJjYWMtNzI3MjIyNmQ1N2Jj',\n 'ZDNkYTJkMDgtMTUyMC00YTYxLWE2ZjQtMWE1MWQxYzYxMzA0',\n 'ZmIyZWUzNmMtNjU1Ny00OWFiLWFiNGMtMTg3NDE4MzJhMjNm',\n 'MTliOTEwODgtMTkyMC00YzlhLTk1NjMtNzBlZjljNGMzNDI5',\n 'YmQ1ZTI3MzEtNGUxZC00OTNhLTllYjMtZjhhNGY2Y2NmOTBi',\n 'ZDU5NDA0NzEtM2RiZi00NmM1LWJlMjktM2EyZTI0MzYxZGZi',\n 'ZWM1MDIxZTItMmMwYS00MTRiLTg0OTMtMWE2MWUwYzE3M2E1',\n 'ODA2YmNjYjYtOTcxOS00YmIzLTg5MzAtZTgwMDQ2YjkyZTNh',\n 'MTZkMTM3OWYtNWUyMi00NzEyLThjZTctNTAxNWY5ZmY3YTM5',\n 'MDYyNTBjM2YtMzIwZi00NWE5LTg3ZjYtOTU3ZTZlNTk0NDI4',\n 'ZDg5NjNjMjItNTMyNC00MTJkLWE2Y2UtNTc4OGZlYzZkZGRl',\n 'YjExM2U3ZmMtZDBjNS00NjI3LWFhZGUtMzhlYzg0ZTU1MmJl',\n 'Mjg5ZjdmYjAtNTRlMS00ZjEyLTk2NmQtNmM2MDA2YjY3NDM3',\n 'OTk1YzIzNGEtYjMxOS00MTFhLTk4ZGItMzFmOTg5MjY4NDc2',\n 'MGI4YmVkNWItM2QxMC00MWU4LTljOGYtNWE1YTUxNGE5ZjEx',\n 'Y2I5NTY5N2UtNGQzMy00NzUwLTljMzAtZjhkYWIwNDVmODU0',\n 'MDEzNTEzZDMtMTgxNS00MTA5LWI4NmYtZDI2NjU0MjdiNTBm',\n 'YTc1NjJkOGQtMTk5My00MThiLWJiZWYtMDJiY2Y5NDQzZTVh',\n 'ZGVjYzUzZDctNGRmYi00NTBkLTg4MzctYWZjMmJlYWRjNjY0',\n 'NWIzYzk4NTUtY2VmYS00MzgyLTgyYWUtYjE5MjdkYTYyNzRh',\n 'YzhmOTBiZDEtZDVlMi00Mzg5LTk1ZDMtNjk4Y2EzMTA5OWUy',\n 'NzNjNThhNTAtNmZjMC00OTZlLTg3OTMtMzI5OGFjNWE5YTNj',\n 'OWY3M2ViODAtYWE5OC00YmNkLTg4ZmUtYWE1MjhmZWUwMjgy',\n 'NjBjNTY1NzEtMTJlMi00MTQ2LWE5MDAtZWQ4NDVlMjk3OGQ4',\n 'YjkyNDJjNDEtYTc5Yi00ZTYzLTlmYmYtNDcyOWIxMzI2NzE1',\n 'MTg4MjMwNDItMTZiMi00NmU2LTg3YTEtYTdlOGI1MmU2YWJi',\n 'MzA4NjM4M2UtNjk5ZC00NTJkLTk0ZjAtNTdmNGMwOWVhYTc2',\n 'MzczNDJhNDQtZTg5Yy00YjUyLWJlZGMtZTQ2MWEyZDE2ZmJm',\n 'MTk5ZjdiNjYtOTViYS00NjBkLWFmNzMtYWIwNzhlYjU3MmFm',\n 'NDZiZTQ0YTUtNDNkOC00YWQ4LWJmMWUtMWM1ZGYyZTA1Yzk1',\n 'YWRkYmI0ZWMtMDQzNC00NWZkLWFjMDItOGU5NjZjMDY2MjVj',\n 'ODE0NDFkY2MtODZiMi00MDhhLTllMmMtNzBiMmQxNDRhMjc5',\n 'MmEyOWJlZGQtNWEzZi00YTliLWFiNmQtMTJiNGFhOGYwOWFm',\n 'MmJkYTM4NmItOWJhNC00NGExLWIzZDQtMGYwNzNmMmFiMjUw',\n 'OTY1OGQ3MDMtY2E1Mi00MWFmLWI4OTAtMDYxZGI2NjRiNmM3',\n 'MjM5MzE0YjYtYjA1NC00NWIyLWFkZmQtM2IyZTZhNGJjZWIz',\n 'YWMyMDU3M2EtOTkxZC00ZDhlLWIzNTAtYzI2YTM5ZTBkMThj',\n 'YTY3MTZiMWMtMzgyZC00ZmViLTg1ZjAtMjRkNzYwMTQ5YjM4',\n 'Y2YwM2Q3ZjUtNzgxMi00NmNlLWIyMjUtYThhZjQzMjE4ODU2',\n 'MDY4N2IwMjgtMjdjNS00NTFmLThiNzMtODMxMTk5NDFmY2Uy',\n 'YzE2NGYzMTQtZjgzNC00NzZjLTk1MzctMjFkOTNiMTUxNjQx',\n 'N2Q1M2JlODQtYzZlMi00ZjFiLWFmYzAtMGU2MjA3N2U2YWMx',\n 'OGQyYzcyMTYtOTk2OC00MzQ5LTgyOWEtZGY0OWUxNzc2ZTQ1',\n 'NjQxMzNiN2EtMWUzYS00MDE5LTgzMGYtODQ0MzFkOWVjODY4',\n 'YWU5YmUyMWUtZDAwMi00ZTNiLWEzMzktOWNhMWY0ZDRmMWFl',\n 'MmVmYmYwNWQtMWJmZC00MzgyLWEyMWMtZmQ4NWI0YmNhZDkx',\n 'YmEwZTBkY2UtMWMxNS00NDYzLWIwYTktNjFlMmM5MWYxNWE2',\n 'OWFmOWJiZjAtNDQ0Yi00ZDMxLWIxMDQtY2RiMGEyN2FhNjMw',\n 'MjAzZjE4YTEtNjk2Ny00YTBiLWIxOWYtNTMzMzFmODZiM2Rj',\n 'NjQ0NWUzNDMtNWRlMS00OTU1LTgxYmUtYTg4NDRiZDNlZTRk',\n 'ZWQ2NDE1NGMtNjVmNC00NjFmLWFiZmItNDU5MWJjNDY5ZDkx',\n 'NDE3ZWUxZmUtN2U3Mi00Yjg4LTkzM2YtYjY0N2RmZWEyMWZj',\n 'MzBhNzdjOWUtM2YyZi00NWJhLWE3ZDktYTY2ZmEwMWRmZDRm',\n 'MGZkYTVhMDUtNzU5Mi00MzViLWE4MGMtNDEyYzAxOTk5MzQx',\n 'MzU4NjQ3ZmItN2NlZS00YjI3LWJjMzgtYTRhMTc4Y2JiMjg2',\n 'MTViZTQ3N2YtYzY2ZS00YjJkLWExNDAtYWNiOWQ3OTNmYTYx',\n 'NWNlYzhlODktMTY3My00NzFkLWEwYzQtMjE1YTk3YWE2NzVh',\n 'MDJmZDJiYjEtYTQyNC00YTZlLWI5NDItMjEwZDc1ZWVlM2Mx',\n 'NGM1ZmM3NWItOGM0OS00OGE1LWFhMjgtMzM4ODllNWE4Zjc1',\n 'YzRjY2ViYmUtYTdhMS00YWMyLTk4M2QtYTMyZjUwMTU5ZTA4',\n 'MjgyZjI4ZTItZGQxYS00OTNhLWE0MDYtZTUxNDBiNmFlMDY4',\n 'ODYyODZhODctMjZiZi00OTk5LTkwODYtMmYyYjBkOTUyMTIw',\n 'ODU4YTkxMmItNzI1OS00MGMyLWI3YWYtMmNhYmQyZDAzNzE4',\n 'YmIyMDc1NTktMzQ0Yi00MTM3LWE0NjgtYTAyOTVkMjczNTY2',\n 'NzA5NGJlNTEtYWQyMi00MWNkLWE1ZmMtZTIyMGMwOWM2NDk4',\n 'YjNmZDFlYjAtMDk5MC00NzE2LTkwODktYzJlOGY4NmFkOGFh',\n 'YmNkMGE3YWEtNjRkNS00MDg4LWE5Y2YtN2NlZWYzMzE0ZmEx',\n 'ODJmMThlOTQtZDYxNi00YzY5LTkxNTAtYjEzNzQ2MTI4Y2Vj',\n 'YjFkZGUzMjktYjFlOC00OTE2LWJkMzQtZDUwYzA0MGZiNTc1',\n 'OWZiY2U3MjQtODIzYS00ZjZhLTk2ODUtZGMxNTI0YmExYTI5',\n 'ZWZmZjNiNzctYTljMC00NDljLWIyNTItMGRmNTZjOWZjZDZh',\n 'ZWY4MzUzNDAtNzE5OS00MzVjLThhZjctZDI5NmYyOTJhN2Jk',\n 'ZTBmY2EyNDUtYTk2Ny00YmYzLWIzNjMtNjJjZDQwM2EwNjQ3',\n 'YzQyZmFmZmQtZGMyYS00YjE5LTg2NmItNDEwM2VhYWQyMDA5',\n 'Y2FiNDc0YWQtYTAyMi00MWUzLWJhMGMtZGQ0MzAyZDY3ZmIw',\n 'Yjc5ZWJlMzMtNDI4MC00Y2UzLWFiMDEtZTg5OTgyNjA1MWQ5',\n 'NjQ3ODVhOWQtMzVkZi00ZmVlLTg3NDAtNjBjNmZlZmIwZGRh',\n 'MWJlMzhkMmQtZDcxMi00M2YxLTgxM2QtM2YzYzgwMTYxNmUw',\n 'MGExNjBhZGMtMDQ1Ni00M2VlLWI4Y2EtOWY4MDlmY2JkZjlj',\n 'MmZjNmQ2MWUtOGEwNC00YzM0LTk4MTMtMWI5OGEzYjgyZThi',\n 'NjZhYTc3NTYtYjRiMS00OTZiLWEyNGUtMjdjMTJjNWY4NzM0',\n 'NGU4MzIxNzctMzExOC00YjRmLTk4MzktZjBmNDU0MjA3N2Qw',\n 'ZDUzMTIyOGYtMTlmMC00YWZmLWJjNmMtNTc5YjdhMzQzYTVi',\n 'MjkyNzQxN2QtMjA0ZC00YmFiLTkwN2ItYzNhNTllOTVmYjkz',\n 'ZjQxMDExZjAtMjFlMC00YjJlLWFhYWEtNzM0MWZiNDUwNDA1',\n 'NzU0MzU0YTAtNDgzNC00ZDk2LThhYjYtNGNhN2YwNTg2NWNh',\n 'ZWZhYmUxZmQtZDFkYy00ZjA2LTk5ZTUtN2JlZTAzZTUwMWE2',\n 'ZTEzZjYxMzYtOTAyMy00YjQyLTkxZDAtMmNmZmY4YjJlODIw',\n 'ZTY3Yjc5ZmQtYjk0Ny00NWEyLTlmM2YtNWM1ZTA1NDZmNzdh',\n 'ZmMwNmMxOWEtYmYzZS00ZGUyLTkwMDYtMWQxYzQyZjYwMDQ0',\n 'NDQ3ZDY1MjUtNTAyOC00YmQwLTkwY2UtZjU1M2ZkZTU4Y2E1',\n 'YTI3NTI0NTctYTE1NS00MDM4LTgyZjQtZjZmNTE0ODZkMWU1',\n 'YzYwNWUxMmMtZTFmOS00OTY2LThjMDYtNWMwMTBiOGVlMDc5',\n 'YmRiZWMzYzctZTkzMi00NzNiLThkMjQtNjExZWUwMDJiZWI0',\n 'MDE0OTYyMjMtOThjMi00MDdlLTlhOGItMjFjMDNlNGNjZGUz',\n 'ZjlmYWFlODgtMDkzNS00NWVkLWJiNDQtNzQwMWEzMDNjZDhm',\n 'ZWQzZjNiNmYtNjM5Zi00MzRmLTg5OGMtMzEwOGFjZjk2MDk2',\n 'ZTdhYmMwODYtMjdmOS00YjRkLWI5ZDktYWE3ODNjZmRmMWRk',\n 'N2NlZThkOTQtOGFmNy00OTc3LWFmNWEtY2UzNTM5MjJkNGJl',\n 'NjgyNDc2YjUtMzQxYi00YjUxLWJlNTMtYmE3Nzk4MTAxMjll',\n 'NjgxOTY1NWYtZTBkZS00YWJiLThjZmMtYTMzMTllM2U1NjQ2',\n 'YTNiYjZkZGMtZWM3My00YTg1LWI5ODktOGU1ZWQyZGZlYzhh',\n 'MDdkYTUzZWQtMTZlMi00NGQyLWIzYjYtMzE4NGM2NzE0Mzhm',\n 'NjI5ZDMxNzMtMmM0NS00NzRhLWI1ZmQtMTVjYjJkOGQ2YWM3',\n 'MzZhMmRlZmQtN2JkNi00OTBmLWI4NTctMGZlMjg0YTIyYmY5',\n 'MzE3MDU5NzgtNjBlOS00MWQxLTlmOGItMDkxNDkzMjllZWVi',\n 'NGE2ZjgwZGEtOGE5YS00NGRmLWE5YzYtMGVkNzhmNzZmN2Ni',\n 'ODllZGMzYmQtMjk2ZC00ODdhLThiMTYtNjAxOGQyMDRhMTg1',\n 'M2IxNmE3ZmYtMzg1Ni00ZDg4LWIyYjMtM2Q1NzkxMzM3OGQ4',\n 'NWFlNzg3MDQtYTY2ZS00MTU3LWE3ZTAtZmUzNGY2OWEzMjhh',\n 'MWU3NDQyYjAtMjU2Mi00YmU3LWE0NDItZDYwZjNhNDdlYTlk',\n 'MjE2ZmEwY2YtNzA0My00OWFhLTlhMjUtMzFhYzYxNmNkYjMz',\n 'ZjQxYzU1NTAtMWIzYy00OGMxLWI5MmQtZGNlZDFjODNhYWI3',\n 'NzZmZDdiNTEtMDE1Ni00MTNlLTk1YjctNjRlNTIzMzE1ZDEw',\n 'MTFkOTZiNGItMjc2NC00YTQ3LTgxZjktYzJhNjg2YTgxNjUz',\n 'NzhlYTFlMzMtZmQzMS00ODVhLWEwMTEtMzUyMmE3ODczYTIx',\n 'NTE2MTAwYTQtZjIzMy00MTVmLWI4M2ItYzUyYjFhYzRhN2U5',\n 'Y2UzODdmZGQtYzA5ZS00YTkxLTkwODQtNDk3YjNiNmYzNTY1',\n 'ZTZhZTE0NmItODhmYS00MTJiLTk1ZTItOTZjN2U2OWQwZTQx',\n 'Y2UwZDY0OGQtYzQxZS00NDNlLTgyOTItMTdlYmJlODhlY2Jj',\n 'MjNhNGI4MWQtYTY0ZS00ODEzLTgwNTktMDgxYWRlYjIzNTNm',\n 'MjAwY2U1MjktYWI1OC00YWUxLWI4OGUtNTMyYTg5YTMwNWMy',\n 'OTY0YjdkZGYtZWQwYi00MGIxLTlhYTktZTA0NzY0NzBjZGU2',\n 'NTgwZjRlYjQtYTdhMC00MmU1LWEwNzktZDYxN2YyNTBkOGQ3',\n 'OTE1YzE0Y2EtY2NkNS00MzcyLTg0OWMtNWM2NDMwNjNhZDlm',\n 'YTUxMzcxYWItYjUwYi00ZDVmLThhOWQtZGQyODgxOWZkODU4',\n 'Mzc5OWI3MmQtNmQ0Mi00NDMzLWIzODUtMTI3YjE2YzNhODRj',\n 'ZmM4MzZkYWMtM2FjYi00Njc5LWE1ZjItMTE4MmU0MzRlY2E0',\n 'MTExY2Y5YjgtZjRhNS00NGU0LWEzMjUtMTc1M2U4YTA2N2My',\n 'ODllNWU1YWItNzk1MC00MjgzLTkyYWEtMTVjZWZhZjFkNTdk',\n 'ZmMxMTczZmUtNDFiNy00ZDQwLWI3OWQtNDA0NDkzNzUzYTM3',\n 'MGIwNDJiNmYtYmQ4Yi00ZTMyLThmNTItMjFmMjY1NWQ4NDli',\n 'N2NjMTQ3YjAtNjE0Ni00MWM0LWI4ZjUtOGZjOTc4ZmQ5MThl',\n 'ZmFkMDRmODktZTNjNS00OTM0LTlkNzgtNTQ3M2Y1MDBmMTM4',\n 'NGJlYWRmN2QtZmE2Yi00MWRmLWJmOGEtYjczZjkzMmQ4ZTZl',\n 'YTI1MGFlYTMtZDBiMS00YWZhLWEyZTMtY2JlMTY1ZDNlNmQ3',\n 'NzM4YjYwZGItMmU0OC00NTBmLTg4ZmItM2IyOTFlNDYzMGI5',\n 'MzM5OWU5Y2ItZDEyMy00YzQ3LTgzNDctYjgzZWQwYTE2NjZj',\n 'MzNhODA3MWYtYjU2Ny00Y2EyLWE1ZWYtODUwYjZlOGQ3NjQ3',\n 'YzdhN2U1MDYtMzgyNi00M2Y2LTliNTktYzhlNzY4MDg4MmRi',\n 'ZTQ5Zjc2ZTctYWYzMS00MGNhLWI1YzAtMjIxMzBjYzM0Yzdi',\n 'YmE0MWM2M2MtYmFlNC00YmVmLTg3ODQtY2MxNjdjNmZhNGZh',\n 'NWVhYWZiMzUtYTkzMi00YTJkLTg5MzYtZmJjNTM4ODEwNTAz',\n 'ZjFiMWMxOWItZDM2YS00NzQ0LTkwNTItM2E2YTY1ODBmNWJh',\n 'OGQ0OWI5ZDItZTQxNy00OWMyLWFlYzYtYTVlN2I4MzZjZWJi',\n 'YWViMzI0Y2MtMGJjOC00M2I2LWI2OWUtZDQwZGNlZGFiMjcw',\n 'Y2VhNDYyOTAtMDE4NS00ZDhlLWIwODAtNWM3Y2E2NDZmY2Nm',\n 'NDQwZGE1YzAtN2ExOC00MWVlLThiMGMtYjdlZTc1NzQwNDJl',\n 'ZWQ4NmU3YWMtMmU5MC00MTQ3LTk1MjAtYzRhZDE3MmNkYTdj',\n 'YTM4ZTRkM2MtOTc1My00OGU0LWE2MGUtYWQ1MjAwMDViNGRj',\n 'NGRkOWJkNjgtNTZmMy00NGE5LThmMmEtMjE5Njc4YjhiZTJh',\n 'ZDQ3ZWY3YzgtNDJlYy00ODc5LWJmN2ItODA0YmNlNDc2MDZj',\n 'ZGM2NzI5NWYtNjVhYy00ZmM3LTg5OTctMGNlMGU0OTI4M2Jl',\n 'ZDY0MTgxMmUtMDZjNC00ZjI2LWJlNTUtNzllZTJkZDM4NzVl',\n 'NmIwZmNjYzktNThmMC00Yjg3LTgyOGEtODhhZjY3Zjc2MmYx',\n 'Y2Q5MjAxMmItNTBlNC00N2EzLTk0YjktODJlZDQ2MjhkNGQ3',\n 'ZTY4NTk4ZTAtMWI1OC00ZTdiLWFkYmYtYjYwYTliNGRlYTk3',\n 'MzFiNTYxZjYtNzA0Mi00MWI5LWI1YTEtZDE3NWQxZjEzNmRl',\n 'MTViMDMxNzMtNzYwMy00Mzg5LTg5YzgtMDc0YWExMzA5Mzlk',\n 'NGQwZjU5OTEtZGIxMi00NjM2LWJiZDYtMzUyN2FjZjYwZjdi',\n 'MDBiYmQ0MGEtM2E0Ni00YWE1LWFmNzUtODg3YjdjODY0NjQ1',\n 'ZGE2YmMxNzgtZGI0MS00ODU0LWI3ODgtNmUyODZjY2U2ZWMx',\n 'Y2FiZDY1NjAtNGFiYi00MzEzLTgzNGEtZDUzYTVjMDNiNWM5']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=docs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Similarity Searches\n",
    "\n",
    "With Azure AI Search, we can now perform similarity searches on the documents we've indexed.\n",
    "\n",
    "### Simple Similarity search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"LangChain's (the company's) goal is to make it as easy as possible to develop LLM applications\"\n",
      "\n",
      "said Harrison Chase, co-founder and CEO of LangChain.\n",
      "\n",
      "\"To that end, we realized pretty early that what was needed - and missing - wasn't just an open source tool like LangChain, but also a complementary platform for managing these new types of applications. To that end, we built LangSmith - which is usable with or without LangChain and let's users easily debug, monitor, test, evaluate, and now (with the recently launched Hub) share and collaborate on their LLM applications.”\n",
      "\n",
      "\n",
      "\n",
      "What Are LangSmith Traces?\n",
      "--------------------------------------------------\n",
      "But these chains werenâ€™t really composable. Sure - we had SequentialChain, but that wasnâ€™t amazingly usable. And under the hood the other chains involved a lot of custom code, which made it tough to enforce a common interface for all chains, and ensure that all had equal levels of batch, streaming, and async support.\n",
      "\n",
      "Today weâ€™re excited to announce a new way of constructing chains. Weâ€™re calling this the LangChain Expression Language (in the same spirit as SQLAlchemyExpressionLanguage). This is a declarative way to truly compose chains - and get streaming, batch, and async support out of the box. You can use all the same existing LangChain constructs to create them.\n",
      "\n",
      "Weâ€™ve included guides on how to work with the interface as well as some examples of using it. Letâ€™s take a look at one of the more common ways below:\n",
      "--------------------------------------------------\n",
      "LangChain Expression Language creates chains that integrate seamlessly with LangSmith. Here is a trace for the above:\n",
      "\n",
      "You can inspect the trace here. Previously, when creating a custom chain there was actually a good bit of work to be done to make sure callbacks were passed through correctly so that it could be traced correctly. With LangChain Expression Language that happens automatically.\n",
      "\n",
      "We've also tried to make this as easy as possible for people to learn by creating a \"LangChain Teacher\" application that will walk you through the basics of getting started with LangChain Expression Language. You can access it here. We'll be open sourcing this soon.\n",
      "\n",
      "We'll also be doing a webinar on this tomorrow. We'll cover the standard interface it exposes, how to use it, and why to use it. Register for that here.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.search(\n",
    "    query=\"What is langchain?\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print('-' * 50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Similarity Search with threshold\n",
    "\n",
    "Queries that don’t meet the threshold requirements are exluded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(page_content='The LangChain library has multiple SQL chains and even an SQL agent aimed at making interacting with data stored in SQL as easy as possible. Here are some relevant links:\\n\\nIntroduction\\n\\nMost of an enterprise’s data is traditionally stored in SQL databases. With the amount of valuable data stored there, business intelligence (BI) tools that make it easy to query and understand the data present there have risen in popularity. But what if you could just interact with a SQL database in natural language? With LLMs today, that is possible. LLMs have an understanding of SQL and are able to write it pretty well. However, there are several issues that make this a non-trivial task.\\n\\nThe Problems\\n\\nSo LLMs can write SQL - what more is needed?\\n\\nUnfortunately, a few things.', metadata={'source': '..\\\\data\\\\langchain_blog_posts\\\\blog.langchain.dev_llms-and-sql_.txt'}), 0.9001867)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.similarity_search_with_relevance_scores(\n",
    "    query=\"How to interact with SQL using langchain?\",\n",
    "    k=3,\n",
    "    score_threshold=.9,\n",
    ")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)\n",
    "    print('-' * 50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hybrid Search\n",
    "\n",
    "In a hybrid search, we can combine the similarity search with a keyword search. Vector and non-vector text fields are queried in parallel, results are merged, and top matches of the unified result set are returned."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LangChain library provides different tools to interact with SQL databases which can be used to build and run queries based on natural language inputs. For example, the standard SQL Toolkit draws from standard best practices that have been extensively covered in this blogpost. However, there is still room for improvement when it comes to building a custom solution and adjusting the generic tools to the specific use case. The advantage of having a plug and play toolkit contrasts with having a solution that is not flexible enough for the user to incorporate their domain-specific knowledge about the databases.\n",
      "--------------------------------------------------\n",
      "The LangChain library has multiple SQL chains and even an SQL agent aimed at making interacting with data stored in SQL as easy as possible. Here are some relevant links:\n",
      "\n",
      "Introduction\n",
      "\n",
      "Most of an enterprise’s data is traditionally stored in SQL databases. With the amount of valuable data stored there, business intelligence (BI) tools that make it easy to query and understand the data present there have risen in popularity. But what if you could just interact with a SQL database in natural language? With LLMs today, that is possible. LLMs have an understanding of SQL and are able to write it pretty well. However, there are several issues that make this a non-trivial task.\n",
      "\n",
      "The Problems\n",
      "\n",
      "So LLMs can write SQL - what more is needed?\n",
      "\n",
      "Unfortunately, a few things.\n",
      "--------------------------------------------------\n",
      "URL: https://blog.langchain.dev/llms-and-sql/\n",
      "Title: LLMs and SQL\n",
      "\n",
      "Francisco Ingham and Jon Luo are two of the community members leading the change on the SQL integrations. We’re really excited to write this blog post with them going over all the tips and tricks they’ve learned doing so. We’re even more excited to announce that we’ll be doing an hour long webinar with them to discuss these learnings and field other related questions. This webinar will be on March 22nd - sign up at the below link:\n",
      "\n",
      "The LangChain library has multiple SQL chains and even an SQL agent aimed at making interacting with data stored in SQL as easy as possible. Here are some relevant links:\n",
      "\n",
      "Introduction\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.hybrid_search(\n",
    "    query=\"How to interact with SQL using langchain?\",\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print('-' * 50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Semantic Ranking\n",
    "In Azure AI Search, semantic ranking measurably improves search relevance by using language understanding to rerank search results.\n",
    "\n",
    "Similarly to what presented in the previous notebook, Azure AI Search uses the context or semantic meaning of a query to compute a new relevance score over preranked results. Scores range from 4 to 0 (high to low), where a higher score indicates higher relevance.\n",
    "\n",
    "\n",
    "Check the [official documentation](https://learn.microsoft.com/en-us/azure/search/semantic-search-overview#how-summaries-are-scored) for more."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LangChain library provides different tools to interact with SQL databases which can be used to build and run queries based on natural language inputs. For example, the standard SQL Toolkit draws from standard best practices that have been extensively covered in this blogpost. However, there is still room for improvement when it comes to building a custom solution and adjusting the generic tools to the specific use case. The advantage of having a plug and play toolkit contrasts with having a solution that is not flexible enough for the user to incorporate their domain-specific knowledge about the databases.\n",
      "**********\n",
      "Score: 3.4577205181121826\n",
      "--------------------------------------------------\n",
      "The LangChain library has multiple SQL chains and even an SQL agent aimed at making interacting with data stored in SQL as easy as possible. Here are some relevant links:\n",
      "\n",
      "Introduction\n",
      "\n",
      "Most of an enterprise’s data is traditionally stored in SQL databases. With the amount of valuable data stored there, business intelligence (BI) tools that make it easy to query and understand the data present there have risen in popularity. But what if you could just interact with a SQL database in natural language? With LLMs today, that is possible. LLMs have an understanding of SQL and are able to write it pretty well. However, there are several issues that make this a non-trivial task.\n",
      "\n",
      "The Problems\n",
      "\n",
      "So LLMs can write SQL - what more is needed?\n",
      "\n",
      "Unfortunately, a few things.\n",
      "**********\n",
      "Score: 3.0471813678741455\n",
      "--------------------------------------------------\n",
      "URL: https://blog.langchain.dev/llms-and-sql/\n",
      "Title: LLMs and SQL\n",
      "\n",
      "Francisco Ingham and Jon Luo are two of the community members leading the change on the SQL integrations. We’re really excited to write this blog post with them going over all the tips and tricks they’ve learned doing so. We’re even more excited to announce that we’ll be doing an hour long webinar with them to discuss these learnings and field other related questions. This webinar will be on March 22nd - sign up at the below link:\n",
      "\n",
      "The LangChain library has multiple SQL chains and even an SQL agent aimed at making interacting with data stored in SQL as easy as possible. Here are some relevant links:\n",
      "\n",
      "Introduction\n",
      "**********\n",
      "Score: 2.8710172176361084\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.semantic_hybrid_search_with_score_and_rerank(\n",
    "    query=\"How to interact with SQL using langchain?\",\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    doc, _, ranker_score = result\n",
    "    print(f\"{doc.page_content}\\n**********\\nScore: {ranker_score}\")\n",
    "    print('-' * 50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LangChain library provides different tools to interact with SQL databases which can be used to build and run queries based on natural language inputs. For example, the standard SQL Toolkit draws from standard best practices that have been extensively covered in this blogpost. However, there is still room for improvement when it comes to building a custom solution and adjusting the generic tools to the specific use case. The advantage of having a plug and play toolkit contrasts with having a solution that is not flexible enough for the user to incorporate their domain-specific knowledge about the databases.\n",
      "--------------------------------------------------\n",
      "The LangChain library has multiple SQL chains and even an SQL agent aimed at making interacting with data stored in SQL as easy as possible. Here are some relevant links:\n",
      "\n",
      "Introduction\n",
      "\n",
      "Most of an enterprise’s data is traditionally stored in SQL databases. With the amount of valuable data stored there, business intelligence (BI) tools that make it easy to query and understand the data present there have risen in popularity. But what if you could just interact with a SQL database in natural language? With LLMs today, that is possible. LLMs have an understanding of SQL and are able to write it pretty well. However, there are several issues that make this a non-trivial task.\n",
      "\n",
      "The Problems\n",
      "\n",
      "So LLMs can write SQL - what more is needed?\n",
      "\n",
      "Unfortunately, a few things.\n",
      "--------------------------------------------------\n",
      "URL: https://blog.langchain.dev/llms-and-sql/\n",
      "Title: LLMs and SQL\n",
      "\n",
      "Francisco Ingham and Jon Luo are two of the community members leading the change on the SQL integrations. We’re really excited to write this blog post with them going over all the tips and tricks they’ve learned doing so. We’re even more excited to announce that we’ll be doing an hour long webinar with them to discuss these learnings and field other related questions. This webinar will be on March 22nd - sign up at the below link:\n",
      "\n",
      "The LangChain library has multiple SQL chains and even an SQL agent aimed at making interacting with data stored in SQL as easy as possible. Here are some relevant links:\n",
      "\n",
      "Introduction\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.semantic_hybrid_search(\n",
    "    query=\"How to interact with SQL using langchain?\",\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print('-' * 50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build a QA Chain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LangChain library provides tools to interact with SQL databases, including SQL chains and an SQL agent. To connect LangChain to SQL, you can use the LangChain Expression Language, which allows you to compose chains and provides streaming, batch, and async support. Here is an example of code to connect LangChain to SQL:\n",
      "\n",
      "```\n",
      "from langchain import SQLAgent\n",
      "\n",
      "# Create an instance of the SQLAgent\n",
      "agent = SQLAgent()\n",
      "\n",
      "# Connect to the SQL database\n",
      "agent.connect(database='your_database', username='your_username', password='your_password')\n",
      "\n",
      "# Execute a SQL query\n",
      "result = agent.execute_query('SELECT * FROM your_table')\n",
      "\n",
      "# Print the result\n",
      "print(result)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv('MODEL_DEPLOYMENT_NAME'),\n",
    "    openai_api_version=openai_api_version,\n",
    "    temperature=0.,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "vector_store.search_type = \"similarity\"\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Don't try to make up the answer, only use the context to answer the question.\n",
    "The pieces of context refer to langchain.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain_base = (\n",
    "    RunnableParallel(\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"Explain how to connect langchain to sql. Show me the code to do that\"\n",
    "print(qa_chain_base.invoke(question))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build a QA Chain with Reranking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To connect LangChain to SQL, you can use the provided code snippet:\n",
      "\n",
      "```\n",
      "from langchain.agents import AgentExecutor, create_sql_agent\n",
      "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
      "from langchain.agents.agent_types import AgentType\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.llms.openai import OpenAI\n",
      "from langchain.sql_database import SQLDatabase\n",
      "\n",
      "def create_agent(db_uri, agent_type=AgentType.OPENAI_FUNCTIONS, verbose=VERBOSE_LANGCHAIN, temperature=0, model=\"gpt-3.5-turbo-0613\"):\n",
      "    db = SQLDatabase.from_uri(db_uri)\n",
      "    toolkit = SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=temperature))\n",
      "    return create_sql_agent(\n",
      "        llm=ChatOpenAI(temperature=temperature, model=model),\n",
      "        toolkit=toolkit,\n",
      "        verbose=verbose,\n",
      "        agent_type=agent_type,\n",
      "    )\n",
      "```\n",
      "\n",
      "Make sure to use your OpenAI key for this and keep it private.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv('MODEL_DEPLOYMENT_NAME'),\n",
    "    openai_api_version=openai_api_version,\n",
    "    temperature=0.,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "vector_store.search_type = \"semantic_hybrid\"\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Don't try to make up the answer, only use the context to answer the question.\n",
    "The pieces of context refer to langchain.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain_base = (\n",
    "    RunnableParallel(\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"Explain how to connect langchain to sql. Show me the code to do that\"\n",
    "print(qa_chain_base.invoke(question))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding sources to the response"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=lambda x: x[\"context\"])\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "res = rag_chain_with_source.invoke(question)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To connect LangChain to SQL, you can use the provided code snippet:\n",
      "\n",
      "```\n",
      "from langchain.agents import AgentExecutor, create_sql_agent\n",
      "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
      "from langchain.agents.agent_types import AgentType\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.llms.openai import OpenAI\n",
      "from langchain.sql_database import SQLDatabase\n",
      "\n",
      "def create_agent(db_uri, agent_type=AgentType.OPENAI_FUNCTIONS, verbose=VERBOSE_LANGCHAIN, temperature=0, model=\"gpt-3.5-turbo-0613\"):\n",
      "    db = SQLDatabase.from_uri(db_uri)\n",
      "    toolkit = SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=temperature))\n",
      "    return create_sql_agent(\n",
      "        llm=ChatOpenAI(temperature=temperature, model=model),\n",
      "        toolkit=toolkit,\n",
      "        verbose=verbose,\n",
      "        agent_type=agent_type,\n",
      "    )\n",
      "```\n",
      "\n",
      "Make sure to use your OpenAI key for this and keep it private.\n"
     ]
    }
   ],
   "source": [
    "print(res[\"answer\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Initializing the LangChain Agent\\n\\nNote: Please use your OpenAI key for this, which should be kept private.\\n\\nHere\\'s the code to initialize the LangChain Agent and connect it to your SQL database.\\n\\nfrom langchain.agents import AgentExecutor, create_sql_agent from langchain.agents.agent_toolkits import SQLDatabaseToolkit from langchain.agents.agent_types import AgentType from langchain.chat_models import ChatOpenAI from langchain.llms.openai import OpenAI from langchain.sql_database import SQLDatabase def create_agent( db_uri, agent_type=AgentType.OPENAI_FUNCTIONS, verbose=VERBOSE_LANGCHAIN, temperature=0, model=\"gpt-3.5-turbo-0613\", ): db = SQLDatabase.from_uri(db_uri) toolkit = SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=temperature)) return create_sql_agent( llm=ChatOpenAI(temperature=temperature, model=model), toolkit=toolkit, verbose=verbose, agent_type=agent_type, )', metadata={'source': '..\\\\data\\\\langchain_blog_posts\\\\blog.langchain.dev_how-to-safely-query-enterprise-data-with-langchain-agents-sql-openai-gretel_.txt', 'captions': {'text': \"here's the code to initialize the langchain agent and connect it to your sql database.  from langchain.agents import agentexecutor, create_sql_agent from langchain.agents.agent_toolkits import sqldatabasetoolkit from langchain.agents.agent_types import agenttype from langchain.chat_models import chatopenai from langchain.llms.openai import openai …\", 'highlights': \"here's the<em> code</em> to initialize the<em> langchain</em> agent and<em> connect</em> it to your<em> sql</em> database.  from langchain.agents<em> import</em> agentexecutor, create_sql_agent from langchain.agents.agent_toolkits<em> import</em> sqldatabasetoolkit from langchain.agents.agent_types<em> import</em> agenttype from langchain.chat_models<em> import</em> chatopenai from langchain.llms.openai<em> import</em> openai …\"}, 'answers': ''}), Document(page_content=\"For this example, I used the Gretel Tabular DP model (notebook, docs) with an epsilon value of 5 for strong privacy guarantees that are great for regulated environments. For maximum accuracy while still maintaining privacy, you can also try the Gretel ACTGAN model (docs), which excels at working with highly dimensional tabular data to enable machine learning and analytics use cases.\\n\\nGetting started: Installation\\n\\nFollow along with our complete notebook in Colab or GitHub.\\n\\nFirst, install dependencies.\\n\\n!pip install -Uqq langchain openai gretel-client !pip install -Uqq smart_open tabulate\\n\\nInitializing the LangChain Agent\\n\\nNote: Please use your OpenAI key for this, which should be kept private.\\n\\nHere's the code to initialize the LangChain Agent and connect it to your SQL database.\", metadata={'source': '..\\\\data\\\\langchain_blog_posts\\\\blog.langchain.dev_how-to-safely-query-enterprise-data-with-langchain-agents-sql-openai-gretel_.txt', 'captions': {'text': \"First, install dependencies.  !pip install -Uqq langchain openai gretel-client !pip install -Uqq smart_open tabulate  Initializing the LangChain Agent  Note: Please use your OpenAI key for this, which should be kept private. Here's the code to initialize the LangChain Agent and connect it to your SQL database..\\x00\", 'highlights': \"First,<em> install</em> dependencies.  !pip<em> install</em> -Uqq<em> langchain</em> openai gretel-client !pip<em> install</em> -Uqq smart_open tabulate  Initializing the<em> LangChain</em> Agent  Note: Please use your OpenAI key for this, which should be kept private. Here's the<em> code</em> to initialize the<em> LangChain</em> Agent and<em> connect</em> it to your<em> SQL</em> database..\\x00\"}, 'answers': ''}), Document(page_content=\"URL: https://blog.langchain.dev/how-to-safely-query-enterprise-data-with-langchain-agents-sql-openai-gretel/\\nTitle: How to Safely Query Enterprise Data with LangChain Agents + SQL + OpenAI + Gretel\\n\\nEditor's Note: This post was written in collaboration with the Gretel team. We're really excited by their approach to combining agent-based methods, LLMs, and synthetic data to enable natural language queries for databases and data warehouses, sans SQL. The post has a really helpful walkthrough (with code!) to bring the ideas to life.\\n\\nAgent-based approaches coupled with large language models (LLMs) are quickly transforming how we interact with databases and data warehouses. Combined, these technologies enable natural language queries to data in your application or business, eliminating the need for SQL expertise to interact with data and even facilitating seamless queries across diverse systems.\", metadata={'source': '..\\\\data\\\\langchain_blog_posts\\\\blog.langchain.dev_how-to-safely-query-enterprise-data-with-langchain-agents-sql-openai-gretel_.txt', 'captions': {'text': \"We're really excited by their approach to combining agent-based methods, LLMs, and synthetic data to enable natural language queries for databases and data warehouses, sans SQL. The post has a really helpful walkthrough (with code!) to bring the ideas to life.\", 'highlights': \"We're really excited by their approach to combining agent-based methods, LLMs, and synthetic data to enable natural language queries for databases and data warehouses,<em> sans SQL.</em> The post has a really helpful walkthrough (with<em> code!)</em> to bring the ideas to life.\"}, 'answers': ''}), Document(page_content='But these chains werenâ€™t really composable. Sure - we had SequentialChain, but that wasnâ€™t amazingly usable. And under the hood the other chains involved a lot of custom code, which made it tough to enforce a common interface for all chains, and ensure that all had equal levels of batch, streaming, and async support.\\n\\nToday weâ€™re excited to announce a new way of constructing chains. Weâ€™re calling this the LangChain Expression Language (in the same spirit as SQLAlchemyExpressionLanguage). This is a declarative way to truly compose chains - and get streaming, batch, and async support out of the box. You can use all the same existing LangChain constructs to create them.\\n\\nWeâ€™ve included guides on how to work with the interface as well as some examples of using it. Letâ€™s take a look at one of the more common ways below:', metadata={'source': '..\\\\data\\\\langchain_blog_posts\\\\blog.langchain.dev_langchain-expression-language_.txt', 'captions': {'text': 'Weâ€™re calling this the LangChain Expression Language (in the same spirit as SQLAlchemyExpressionLanguage). This is a declarative way to truly compose chains - and get streaming, batch, and async support out of the box. You can use all the same existing LangChain constructs to create them.', 'highlights': 'Weâ€™re calling this the<em> LangChain Expression Language</em> (in the same spirit as<em> SQLAlchemyExpressionLanguage).</em> This is a declarative way to truly compose chains - and get streaming, batch, and async support out of the box. You can use all the same existing<em> LangChain</em> constructs to create them.'}, 'answers': ''}), Document(page_content='The LangChain library provides different tools to interact with SQL databases which can be used to build and run queries based on natural language inputs. For example, the standard SQL Toolkit draws from standard best practices that have been extensively covered in this blogpost. However, there is still room for improvement when it comes to building a custom solution and adjusting the generic tools to the specific use case. The advantage of having a plug and play toolkit contrasts with having a solution that is not flexible enough for the user to incorporate their domain-specific knowledge about the databases.', metadata={'source': '..\\\\data\\\\langchain_blog_posts\\\\blog.langchain.dev_incorporating-domain-specific-knowledge-in-sql-llm-solutions_.txt', 'captions': {'text': 'The LangChain library provides different tools to interact with SQL databases which can be used to build and run queries based on natural language inputs. For example, the standard SQL Toolkit draws from standard best practices that have been extensively covered in this blogpost. However, there is still room for improvement when it comes to building a custom solution and adjusting the generic tools to the specific use case. The advantage of having a plug and play toolkit contrasts with having a solution that is not flexible enough for the user to incorporate their domain-specific knowledge about the databases..', 'highlights': 'The<em> LangChain</em> library provides different tools to interact with SQL databases which can be used to build and run queries based on natural language inputs. For example, the standard<em> SQL Toolkit</em> draws from standard best practices that have been extensively covered in this blogpost. However, there is still room for improvement when it comes to building a custom solution and adjusting the generic tools to the specific use case. The advantage of having a plug and play toolkit contrasts with having a solution that is not flexible enough for the user to incorporate their domain-specific knowledge about the databases..'}, 'answers': ''})]\n"
     ]
    }
   ],
   "source": [
    "print(res[\"context\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\langchain_blog_posts\\blog.langchain.dev_how-to-safely-query-enterprise-data-with-langchain-agents-sql-openai-gretel_.txt\n",
      "..\\data\\langchain_blog_posts\\blog.langchain.dev_how-to-safely-query-enterprise-data-with-langchain-agents-sql-openai-gretel_.txt\n",
      "..\\data\\langchain_blog_posts\\blog.langchain.dev_how-to-safely-query-enterprise-data-with-langchain-agents-sql-openai-gretel_.txt\n",
      "..\\data\\langchain_blog_posts\\blog.langchain.dev_langchain-expression-language_.txt\n",
      "..\\data\\langchain_blog_posts\\blog.langchain.dev_incorporating-domain-specific-knowledge-in-sql-llm-solutions_.txt\n"
     ]
    }
   ],
   "source": [
    "for doc in res[\"context\"]:\n",
    "    print(doc.metadata['source'])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
