{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List, Dict\n",
    "\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "openai_api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "openai_api_version = '2023-08-01-preview'\n",
    "model_deployment_name = os.getenv('MODEL_DEPLOYMENT_NAME')\n",
    "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "client = AzureOpenAI(\n",
    "    api_key = openai_api_key,\n",
    "    api_version=openai_api_version,\n",
    ")\n",
    "\n",
    "def get_chat_with_conversation(\n",
    "        text,\n",
    "        temperature: float = 0.2,\n",
    "        **model_kwargs\n",
    ") -> str:\n",
    "    try:\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": '\"\"\"'+ str(text) + '\"\"\"'}\n",
    "        ]\n",
    "        response = client.chat.completions.create(model=model_deployment_name,\n",
    "                                                  messages=messages)\n",
    " \n",
    "        return response.choices[0].message.content\n",
    "    except openai.OpenAIError as e: # this is the base class of any openai exception\n",
    "        print(f\"The call to the Chat Completion API failed as a consequence \"\n",
    "              f\"of the following exception: {e}\")\n",
    "        \n",
    "def user_request():\n",
    "    # Take request\n",
    "    request = input(\"\\nEnter an instruction\"\n",
    "                    \"(or 'quit'):\")\n",
    "    if request.lower() == \"quit\":\n",
    "        raise KeyboardInterrupt()\n",
    "    return request\n",
    "\n",
    "def user_reply_success(request,response):\n",
    "    # Create and print user reply\n",
    "    reply = f\"{request}:\\n{response}\"\n",
    "    print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safety and Privacy with LangChain\n",
    "\n",
    "In this notebook we will use our privacy (PII entity recognizer and anonymizer) and toxic text classifier `tensor-trek/distilbert-toxicity-classifier` along with LangChain to implement checks of the text going into our LLM and text generated by the LLM. For this example we will use a custom `PrivacyAndSafetyChain` chain that implements the two checks.\n",
    "\n",
    "\n",
    "Let's install some dependencies first\n",
    "- You will need `transformers`, PyTorch, `langchain`, `presidio-analyzer`, `presidio-anonymizer`, and `spacy` libraries\n",
    "- You will also need the spacy `en_core_web_lg` model. You can also work with `en_core_web_md` model here.\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/LCEL1.png\" width=\"700\" align=\"center\"/>&nbsp;&nbsp;\n",
    "</div>\n",
    "Now, let's wrap it up together and create our app using LangChain Expression Language (LCEL).\n",
    "\n",
    "The chain bellow is  containing :\n",
    "\n",
    "<br>\n",
    "<img src=\"assets/PrivacySafetyChain.png\" width=\"950\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the `PrivacyAndSafetyChain` custom chain\n",
    "\n",
    "The directory `chains` contains files that implements the custom Chain.\n",
    "- The `privacy_and_safety.py` file contains a Subclass of the base LangChain `Chain` class\n",
    "- The `check.py` file contains the actual toxic text classification and PII entity detection and anonymization\n",
    "\n",
    "Let's have a look to the `check.py` file.\n",
    "\n",
    "Let's import and initialize `PrivacyAndSafetyChain` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Configuration for `PrivacyAndSafetyChain`\n",
    "\n",
    "We can customize the behavior of `PrivacyAndSafetyChain` via the following parameters\n",
    "\n",
    "- `pii_mask_character`, the character used to perform anonymization of PII entities. Default is `*`\n",
    "- `pii_labels` if you wish to specify a specific list of PII entity types, then a list of entity types. For a full list of PII entity labels refer [Presidio supported entities](https://microsoft.github.io/presidio/supported_entities/). Defaults to ALL entities.\n",
    "- `fail_on_pii` a boolean flag which will make the chain fail if PII is detected. Defaults to `False`.\n",
    "- `pii_threshold` the confidence score threshold for PII entity recognition. Defaults to 50%\n",
    "- `toxicity_threshold` the confidence score threshold for toxicity classification. Defaults to 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chains import PrivacyAndSafetyChain\n",
    "\n",
    "safety_privacy = PrivacyAndSafetyChain(\n",
    "    verbose=True,\n",
    "    pii_mask_character=\"#\",\n",
    "    pii_labels = [\"PHONE_NUMBER\", \"EMAIL_ADDRESS\", \"PERSON\", \"US_SSN\"],\n",
    "    fail_on_pii = True,\n",
    "    pii_threshold = 0.5,\n",
    "    toxicity_threshold = 0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an instruction(or 'quit'):What is John Doe's email address, phone number and SSN from the following text? John Doe, a resident of 1234 Elm Street in Springfield, recently celebrated his birthday on January 1st. Turning 43 this year, John reflected on the years gone by. He often shares memories of his younger days with his close friends through calls on his phone, (555) 123-4567. Meanwhile, during a casual evening, he received an email at johndoe@example.com reminding him of an old acquaintance's reunion. As he navigated through some old documents, he stumbled upon a paper that listed his SSN as 338-12-6789, reminding him to store it in a safer place.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new PrivacyAndSafetyChain chain...\u001b[0m\n",
      "Running PrivacyAndSafetyChain...\n",
      "(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /tensor-trek/distilbert-toxicity-classifier/resolve/main/tokenizer_config.json (Caused by SSLError(SSLError(5, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:1007)')))\"), '(Request ID: 84c5f1b7-fc0b-4007-873a-cb077c24ec03)')\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"{question}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "chain = (\n",
    "    prompt \n",
    "    | safety_privacy \n",
    "    | {\"input\": (lambda x: x['output'] )}\n",
    "    | get_chat_with_conversation\n",
    "    | safety_privacy \n",
    ")\n",
    "\n",
    "\n",
    "while True : \n",
    "    try:\n",
    "        input_user = user_request()\n",
    "        response = chain.invoke({\"question\": input_user})\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nQuit!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "    else:\n",
    "\n",
    "        print(\"\\n The answer is: \\n\", response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of prompts:\n",
    "\n",
    "I hate my coworkers, can you help me get them fired?\n",
    "\n",
    "\n",
    "\n",
    "What is John Doe's email address, phone number and SSN from the following text?\n",
    "John Doe, a resident of 1234 Elm Street in Springfield, recently celebrated his birthday on January 1st. Turning 43 this year, John reflected on the years gone by. He often shares memories of his younger days with his close friends through calls on his phone, (555) 123-4567. Meanwhile, during a casual evening, he received an email at johndoe@example.com reminding him of an old acquaintance's reunion. As he navigated through some old documents, he stumbled upon a paper that listed his SSN as 338-12-6789, reminding him to store it in a safer place.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chains import PrivacyAndSafetyChain\n",
    "\n",
    "safety_privacy = PrivacyAndSafetyChain(\n",
    "    verbose=True,\n",
    "    pii_mask_character=\"#\",\n",
    "    pii_labels = [\"PHONE_NUMBER\", \"EMAIL_ADDRESS\", \"PERSON\", \"US_SSN\"],\n",
    "    fail_on_pii = False,\n",
    "    pii_threshold = 0.5,\n",
    "    toxicity_threshold = 0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"{question}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "chain = (\n",
    "    prompt \n",
    "    | safety_privacy \n",
    "    | {\"input\": (lambda x: x['output'] )}\n",
    "    | get_chat_with_conversation\n",
    "    | safety_privacy \n",
    ")\n",
    "\n",
    "\n",
    "while True : \n",
    "    try:\n",
    "        input_user = user_request()\n",
    "        response = chain.invoke({\"question\": input_user})\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nQuit!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "    else:\n",
    "        print(\"\\n The answer is: \\n\", response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
